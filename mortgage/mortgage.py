# Derived from https://github.com/fschlimb/scale-out-benchs

import argparse
import os
import pathlib
import sys
import time
from glob import glob
from io import StringIO

import numpy as np
import pandas as pd
from pandas.api.types import CategoricalDtype

import report
from pymapd import connect

import_query_template = "COPY %s FROM '%s' WITH (DELIMITER='|');"


def run_pd_workflow(quarter, year, perf_file, fragment_size):
    t1 = time.time()
    # Load names
    con.execute("DROP TABLE IF EXISTS names;")
    pd_load_names(con, fragment_size)
    # Load acquisition
    con.execute("DROP TABLE IF EXISTS acq;")
    acquisition_path = os.path.join(
        data_directory, "acq", "Acquisition_" + str(year) + "Q" + str(quarter) + ".txt"
    )
    pd_load_acquisition_csv(acquisition_path, con, fragment_size)
    # Load perf
    con.execute("DROP TABLE IF EXISTS perf;")
    pd_load_performance_csv(perf_file, con, fragment_size)
    print("read time", (time.time() - t1) * 1000)

    t1 = time.time()
    con.execute("DROP TABLE IF EXISTS acqtemp;")
    con.execute(
        "CREATE TABLE acqtemp AS SELECT loan_id,orig_channel,year_quarter,names.seller_name AS seller_name,new_seller_name FROM acq  LEFT JOIN names ON acq.seller_name = names.seller_name;"
    )
    con.execute("DROP TABLE IF EXISTS acq;")
    con.execute("ALTER TABLE acqtemp RENAME TO acq;")
    con.execute("DROP TABLE IF EXISTS names;")
    # acq_pdf = acq_pdf.merge(names, how='left', on=['seller_name'])
    # acq_pdf.drop(columns=['seller_name'], inplace=True)
    # acq_pdf['seller_name'] = acq_pdf['new_seller_name']
    # acq_pdf.drop(columns=['new_seller_name'], inplace=True)
    # DECLARE @pdf nvarchar(30)
    # SET pdf = perf_df_tmp
    create_ever_features()
    create_delinq_features()
    join_ever_delinq_features()
    create_joined_df()
    create_12_mon_features()
    combine_joined_12_mon()
    final_performance_delinquency()
    join_perf_acq_pdfs()
    print("compute time", (time.time() - t1) * 1000)
    final_pdf = last_mile_cleaning(final_pdf)
    exec_time = (time.time() - t1) * 1000
    print("compute time with copy to host", exec_time)
    return final_pdf, exec_time


def pd_load_performance_csv(performance_path, con, fragment_size):
    """ Loads performance data

    Returns
    -------
    PD DataFrame
    """

    # cols = [
    #     "loan_id", "monthly_reporting_period", "servicer", "interest_rate", "current_actual_upb",
    #     "loan_age", "remaining_months_to_legal_maturity", "adj_remaining_months_to_maturity",
    #     "maturity_date", "msa", "current_loan_delinquency_status", "mod_flag", "zero_balance_code",
    #     "zero_balance_effective_date", "last_paid_installment_date", "foreclosed_after",
    #     "disposition_date", "foreclosure_costs", "prop_preservation_and_repair_costs",
    #     "asset_recovery_costs", "misc_holding_expenses", "holding_taxes", "net_sale_proceeds",
    #     "credit_enhancement_proceeds", "repurchase_make_whole_proceeds", "other_foreclosure_proceeds",
    #     "non_interest_bearing_upb", "principal_forgiveness_upb", "repurchase_make_whole_proceeds_flag",
    #     "foreclosure_principal_write_off_amount", "servicing_activity_indicator"
    # ]
    # dtypes = {
    #     "loan_id": np.int64,
    #     "monthly_reporting_period": str,
    #     "servicer": str,
    #     "interest_rate": np.float64,
    #     "current_actual_upb": np.float64,
    #     "loan_age": np.float64,
    #     "remaining_months_to_legal_maturity": np.float64,
    #     "adj_remaining_months_to_maturity": np.float64,
    #     "maturity_date": str,
    #     "msa": np.float64,
    #     "current_loan_delinquency_status": np.int32,
    #     "mod_flag": CategoricalDtype(['N', 'Y']),
    #     "zero_balance_code": CategoricalDtype(['01', '02', '06', '09', '03', '15', '16']),
    #     "zero_balance_effective_date": str,
    #     "last_paid_installment_date": str,
    #     "foreclosed_after": str,
    #     "disposition_date": str,
    #     "foreclosure_costs": np.float64,
    #     "prop_preservation_and_repair_costs": np.float64,
    #     "asset_recovery_costs": np.float64,
    #     "misc_holding_expenses": np.float64,
    #     "holding_taxes": np.float64,
    #     "net_sale_proceeds": np.float64,
    #     "credit_enhancement_proceeds": np.float64,
    #     "repurchase_make_whole_proceeds": np.float64,
    #     "other_foreclosure_proceeds": np.float64,
    #     "non_interest_bearing_upb": np.float64,
    #     "principal_forgiveness_upb": np.float64,
    #     "repurchase_make_whole_proceeds_flag": CategoricalDtype(['N', 'Y']),
    #     "foreclosure_principal_write_off_amount": np.float64,
    #     "servicing_activity_indicator": CategoricalDtype(['N', 'Y']),
    # }

    # print(performance_path)

    # p = pd.read_csv(performance_path, names=cols, delimiter='|', dtype=dtypes, parse_dates=[1,8,13,14,15,16])
    # return p

    create_table_names_temlate = """
CREATE TABLE perf (
    loan_id BIGINT,
    monthly_reporting_period DATE ENCODING DAYS(32),
    servicer TEXT ENCODING DICT(16),
    interest_rate DOUBLE,
    current_actual_upb DOUBLE,
    loan_age DOUBLE,
    remaining_months_to_legal_maturity DOUBLE,
    adj_remaining_months_to_maturity DOUBLE,
    maturity_date TEXT ENCODING DICT(16),
    msa DOUBLE,
    current_loan_delinquency_status INTEGER,
    mod_flag TEXT ENCODING DICT(16),
    zero_balance_code TEXT ENCODING DICT(16),
    zero_balance_effective_date DATE ENCODING DAYS(32),
    last_paid_installment_date DATE ENCODING DAYS(32),
    foreclosed_after DATE ENCODING DAYS(32),
    disposition_date DATE ENCODING DAYS(32),
    foreclosure_costs DOUBLE,
    prop_preservation_and_repair_costs DOUBLE,
    asset_recovery_costs DOUBLE,
    misc_holding_expenses DOUBLE,
    holding_taxes DOUBLE,
    net_sale_proceeds DOUBLE,
    credit_enhancement_proceeds DOUBLE,
    repurchase_make_whole_proceeds DOUBLE,
    other_foreclosure_proceeds DOUBLE,
    non_interest_bearing_upb DOUBLE,
    principal_forgiveness_upb DOUBLE,
    repurchase_make_whole_proceeds_flag TEXT ENCODING DICT(16),
    foreclosure_principal_write_off_amount DOUBLE,
    servicing_activity_indicator TEXT ENCODING DICT(16)
) WITH (FRAGMENT_SIZE= ##FRAGMENT_SIZE## );
"""
    create_table_names = create_table_names_temlate.replace(
        "##FRAGMENT_SIZE##", str(fragment_size)
    )
    import_query = import_query_template % ("perf", performance_path)

    con.execute(create_table_names)
    con.execute(import_query)


def pd_load_acquisition_csv(acquisition_path, con, fragment_size):
    """ Loads acquisition data

    Returns
    -------
    PD DataFrame
    """

    # columns = [
    #     'loan_id', 'orig_channel', 'seller_name', 'orig_interest_rate', 'orig_upb', 'orig_loan_term',
    #     'orig_date', 'first_pay_date', 'orig_ltv', 'orig_cltv', 'num_borrowers', 'dti', 'borrower_credit_score',
    #     'first_home_buyer', 'loan_purpose', 'property_type', 'num_units', 'occupancy_status', 'property_state',
    #     'zip', 'mortgage_insurance_percent', 'product_type', 'coborrow_credit_score', 'mortgage_insurance_type',
    #     'relocation_mortgage_indicator', 'year_quarter'
    # ]
    # dtypes = {
    #     'loan_id': np.int64,
    #     'orig_channel': CategoricalDtype(['B', 'C', 'R']),
    #     'seller_name': str,
    #     'orig_interest_rate': np.float64,
    #     'orig_upb': np.int64,
    #     'orig_loan_term': np.int64,
    #     'orig_date': str,
    #     'first_pay_date': str,
    #     'orig_ltv': np.float64,
    #     'orig_cltv': np.float64,
    #     'num_borrowers': np.float64,
    #     'dti': np.float64,
    #     'borrower_credit_score': np.float64,
    #     'first_home_buyer': CategoricalDtype(['N', 'U', 'Y']),
    #     'loan_purpose': CategoricalDtype(['C', 'P', 'R', 'U']),
    #     'property_type': CategoricalDtype(['CO', 'CP', 'MH', 'PU', 'SF']),
    #     'num_units': np.int64,
    #     'occupancy_status': CategoricalDtype(['I', 'P', 'S']),
    #     'property_state': CategoricalDtype(
    #         ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA', 'HI',
    #         'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI', 'MN',
    #         'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV', 'NY', 'OH',
    #         'OK', 'OR', 'PA', 'PR', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VA', 'VI',
    #         'VT', 'WA', 'WI', 'WV', 'WY']),
    #     'zip': np.int64,
    #     'mortgage_insurance_percent': np.float64,
    #     'product_type': CategoricalDtype(['FRM']),
    #     'coborrow_credit_score': np.float64,
    #     'mortgage_insurance_type': np.float64,
    #     'relocation_mortgage_indicator': CategoricalDtype(['N', 'Y']),
    #     'year_quarter': np.int64
    # }

    # print(acquisition_path)

    # a = pd.read_csv(acquisition_path, names=columns, delimiter='|', dtype=dtypes, parse_dates=[6,7], error_bad_lines=True, warn_bad_lines=True, na_filter=True)
    # return a

    create_table_names_temlate = """
CREATE TABLE acq (
    loan_id BIGINT,
    orig_channel TEXT ENCODING DICT(32),
    seller_name TEXT ENCODING DICT(32),
    orig_interest_rate DOUBLE,
    orig_upb BIGINT,
    orig_loan_term BIGINT,
    orig_date DATE ENCODING DAYS(32),
    first_pay_date DATE ENCODING DAYS(32),
    orig_ltv DOUBLE,
    orig_cltv DOUBLE,
    num_borrowers DOUBLE,
    dti DOUBLE,
    borrower_credit_score DOUBLE,
    first_home_buyer TEXT ENCODING DICT(32),
    loan_purpose TEXT ENCODING DICT(32),
    property_type TEXT ENCODING DICT(32),
    num_units BIGINT,
    occupancy_status TEXT ENCODING DICT(32),
    property_state TEXT ENCODING DICT(32),
    zip BIGINT,
    mortgage_insurance_percent DOUBLE,
    product_type TEXT ENCODING DICT(32),
    coborrow_credit_score DOUBLE,
    mortgage_insurance_type DOUBLE,
    relocation_mortgage_indicator TEXT ENCODING DICT(32),
    year_quarter BIGINT
) WITH (FRAGMENT_SIZE= ##FRAGMENT_SIZE## );
"""
    create_table_names = create_table_names_temlate.replace(
        "##FRAGMENT_SIZE##", str(fragment_size)
    )
    import_query = import_query_template % ("acq", acquisition_path)

    con.execute(create_table_names)
    con.execute(import_query)


def pd_load_names(con, fragment_size):
    """ Loads names used for renaming the banks

     Returns
    -------
    PD DataFrame
    """

    # cols = [
    #     'seller_name', 'new_seller_name'
    # ]

    # dtypes = {'seller_name':str, 'new_seller_name':str}

    # n = pd.read_csv(os.path.join(data_directory, "names.csv"), names=cols, delimiter='|', dtype=dtypes)
    # return n

    create_table_names_temlate = """
CREATE TABLE names (
    seller_name TEXT ENCODING DICT(32),
    new_seller_name TEXT ENCODING DICT(32)
) WITH (FRAGMENT_SIZE= ##FRAGMENT_SIZE## );
"""
    create_table_names = create_table_names_temlate.replace(
        "##FRAGMENT_SIZE##", str(fragment_size)
    )
    import_query = import_query_template % ("names", os.path.join(data_directory, "names.csv"),)

    con.execute(create_table_names)
    con.execute(import_query)


def create_ever_features():
    # everdf = pdf[['loan_id', 'current_loan_delinquency_status']]
    con.execute("DROP TABLE IF EXISTS everdf;")
    con.execute("DROP TABLE IF EXISTS everdftemp1;")
    # con.create_table('everdf', everdf);
    con.execute(
        "CREATE TABLE everdf AS (SELECT loan_id, current_loan_delinquency_status FROM perf);"
    )
    con.execute(
        "CREATE TABLE everdftemp1 AS (SELECT loan_id, MAX(current_loan_delinquency_status) AS current_loan_delinquency_status FROM everdf GROUP BY loan_id);"
    )
    # everdf = everdf.groupby('loan_id').max()
    con.execute("DROP TABLE IF EXISTS pdf;")
    # del(pdf)
    # con.execute('ALTER TABLE everdftemp1 ADD (ever_30 INT   ENCODING DICT);');
    con.execute("DROP TABLE IF EXISTS ever_30;")
    con.execute("DROP TABLE IF EXISTS ever_90;")
    con.execute("DROP TABLE IF EXISTS ever_180;")
    con.execute("DROP TABLE IF EXISTS ever_30temp;")
    con.execute("DROP TABLE IF EXISTS ever_90temp;")
    con.execute("DROP TABLE IF EXISTS ever_180temp;")
    # con.execute()
    con.execute(
        "CREATE TABLE ever_30 AS SELECT loan_id,current_loan_delinquency_status FROM everdf where current_loan_delinquency_status >= 1;"
    )
    con.execute(
        "UPDATE ever_30 SET current_loan_delinquency_status = CAST(current_loan_delinquency_status AS BIGINT);"
    )
    con.execute(
        "CREATE TABLE ever_90 AS SELECT loan_id,current_loan_delinquency_status FROM everdf where current_loan_delinquency_status >= 3;"
    )
    con.execute(
        "UPDATE ever_90 SET current_loan_delinquency_status = CAST(current_loan_delinquency_status AS BIGINT);"
    )
    con.execute(
        "CREATE TABLE ever_180 AS SELECT loan_id,current_loan_delinquency_status FROM everdf where current_loan_delinquency_status >= 6;"
    )
    con.execute(
        "UPDATE ever_180 SET current_loan_delinquency_status = CAST(current_loan_delinquency_status AS BIGINT);"
    )
    con.execute(
        "CREATE TABLE ever_30temp AS SELECT everdftemp1.loan_id AS loan_id,everdftemp1.current_loan_delinquency_status AS current_loan_delinquency_status ,ever_30.current_loan_delinquency_status AS ever_30 FROM ever_30  LEFT JOIN everdftemp1 ON ever_30.loan_id = everdftemp1.loan_id;"
    )
    con.execute(
        "CREATE TABLE ever_90temp AS SELECT ever_30temp.loan_id AS loan_id,ever_30temp.current_loan_delinquency_status AS current_loan_delinquency_status,ever_30temp.current_loan_delinquency_status AS ever_30 ,ever_90.current_loan_delinquency_status AS ever_90 FROM ever_30temp  LEFT JOIN ever_90 ON ever_90.loan_id = ever_30temp.loan_id;"
    )
    con.execute(
        "CREATE TABLE ever_180temp AS SELECT ever_90temp.loan_id AS loan_id,ever_90temp.current_loan_delinquency_status AS current_loan_delinquency_status,ever_90temp.ever_30 AS ever_30,ever_90temp.ever_90 ,ever_180.current_loan_delinquency_status AS ever_180 FROM ever_90temp  LEFT JOIN ever_180 ON ever_180.loan_id = ever_90temp.loan_id;"
    )
    con.execute("DROP TABLE IF EXISTS everdftemp1;")
    con.execute("DROP TABLE IF EXISTS mergetest;")
    # con.execute('CREATE TABLE mergetest');
    # con.execute('ALTER TABLE ever_30 ADD COLUMN test INT;');
    # con.execute('INSERT INTO ever_30 (test) select current_loan_delinquency_status FROM everdf;');
    con.execute("DROP TABLE IF EXISTS everdf1;")
    # con.execute('DROP TABLE IF EXISTS acq;');
    con.execute("ALTER TABLE ever_180temp  RENAME TO everdf1;")
    # con.execute('ALTER TABLE everdftemp1 RENAME TO everdf;');
    # con.execute('CREATE TABLE everdftemp1 AS SELECT loan_id FROM everdf;');
    # con.execute('CREATE TABLE everdftemp1 AS SELECT loan_id FROM everdf;');
    # con.execute('CREATE TABLE everdftemp1 AS SELECT loan_id FROM everdf;');
    # con.execute('DROP TABLE IF EXISTS everdf;');
    # con.execute('ALTER TABLE ever_180temp  RENAME TO everdftemp1 ;');
    con.execute("DROP TABLE IF EXISTS ever_30;")
    con.execute("DROP TABLE IF EXISTS ever_90;")
    con.execute("DROP TABLE IF EXISTS ever_180;")
    con.execute("DROP TABLE IF EXISTS ever_30temp;")
    con.execute("DROP TABLE IF EXISTS ever_90temp;")
    con.execute("DROP TABLE IF EXISTS ever_180temp;")
    # everdf.drop(columns=['current_loan_delinquency_status'], inplace=True)


def create_delinq_features():
    # delinq_pdf = pdf[['loan_id', 'monthly_reporting_period', 'current_loan_delinquency_status']]
    con.execute("DROP TABLE IF EXISTS delinq;")
    con.execute("DROP TABLE IF EXISTS delinq_30 ;")
    con.execute("DROP TABLE IF EXISTS delinq_90 ;")
    con.execute("DROP TABLE IF EXISTS delinq_180 ;")

    # con.create_table('delinq',pdf);
    con.execute(
        "CREATE TABLE delinq AS (SELECT loan_id, monthly_reporting_period, current_loan_delinquency_status FROM perf);"
    )
    # delinq_30 = delinq_pdf.query('current_loan_delinquency_status >= 1')[['loan_id', 'monthly_reporting_period']].groupby('loan_id').min()
    con.execute(
        "CREATE TABLE delinq_30 AS (SELECT loan_id, MIN(monthly_reporting_period) AS monthly_reporting_period, monthly_reporting_period AS delinquency_30 FROM delinq WHERE current_loan_delinquency_status >= 1 GROUP BY loan_id,delinquency_30);"
    )
    # delinq_30['delinquency_30'] = delinq_30['monthly_reporting_period']
    con.execute(
        "CREATE TABLE delinq_90 AS (SELECT loan_id, MIN(monthly_reporting_period) AS monthly_reporting_period, monthly_reporting_period AS delinquency_90 FROM delinq WHERE current_loan_delinquency_status >= 3 GROUP BY loan_id,delinquency_90);"
    )
    con.execute(
        "CREATE TABLE delinq_180 AS (SELECT loan_id, MIN(monthly_reporting_period) AS monthly_reporting_period, monthly_reporting_period AS delinquency_180 FROM delinq WHERE current_loan_delinquency_status >= 6 GROUP BY loan_id,delinquency_180);"
    )

    # delinq_90 = delinq_pdf.query('current_loan_delinquency_status >= 3')[['loan_id', 'monthly_reporting_period']].groupby('loan_id').min()
    # delinq_90['delinquency_90'] = delinq_90['monthly_reporting_period']
    # delinq_90.drop(columns=['monthly_reporting_period'], inplace=True)
    # delinq_180 = delinq_pdf.query('current_loan_delinquency_status >= 6')[['loan_id', 'monthly_reporting_period']].groupby('loan_id').min()
    # delinq_180['delinquency_180'] = delinq_180['monthly_reporting_period']
    # delinq_180.drop(columns=['monthly_reporting_period'], inplace=True)
    con.execute("DROP TABLE IF EXISTS delinq_merge;")
    con.execute(
        "CREATE TABLE delinq_merge AS (SELECT delinq_30.delinquency_30 AS delinquency_30, delinq_30.loan_id AS loan_id, delinq_90.delinquency_90 AS delinquency_90 FROM delinq_30 LEFT JOIN delinq_90 ON delinq_30.loan_id=delinq_90.loan_id);"
    )
    # delinq_merge = delinq_30.merge(delinq_90, how='left', on=['loan_id'])
    # UPDATE UFOs SET shape='ovate' where shape='eggish'; 23:59:59.999
    # con.execute(' EXTRACT MONTH FROM 2018-08-01;');
    con.execute("UPDATE delinq_merge SET delinquency_90 = NULL WHERE delinquency_90 = NULL")
    # delinq_merge['delinquency_90'] = delinq_merge['delinquency_90'].fillna(np.dtype('datetime64[ms]').type('1970-01-01').astype('datetime64[ms]'))
    con.execute("DROP TABLE IF EXISTS delinq_mergetemp;")
    con.execute(
        "CREATE TABLE delinq_mergetemp AS (SELECT delinq_merge.delinquency_30 AS delinquency_30, delinq_merge.loan_id AS loan_id, delinq_merge.delinquency_90 AS delinquency_90, delinq_180.delinquency_180 AS delinquency_180 FROM delinq_merge LEFT JOIN delinq_180 ON delinq_merge.loan_id= delinq_180.loan_id);"
    )
    # con.execute('UPDATE delinq_merge SET  delinquency_90 = NULL where  delinquency_90 = NULL');
    # delinq_merge = delinq_merge.merge(delinq_180, how='left', on=['loan_id'])
    con.execute("DROP TABLE IF EXISTS delinq_merge;")
    con.execute("ALTER TABLE delinq_mergetemp RENAME TO delinq_merge;")
    # t =('test1;');
    # con.execute('UPDATE delinq_merge SET  delinquency_180 = NULL where  delinquency_180 = NULL');
    # print(row=con.execute("SELECT * from delinq_merge"));
    # rows=con.fetchall();
    # delinq_merge['delinquency_180'] = delinq_merge['delinquency_180'].fillna(np.dtype('datetime64[ms]').type('1970-01-01').astype('datetime64[ms]'))
    # del(delinq_30)
    # del(delinq_90)
    # del(delinq_180)
    con.execute("DROP TABLE IF EXISTS delinq_30;")
    con.execute("DROP TABLE IF EXISTS delinq_90;")
    con.execute("DROP TABLE IF EXISTS delinq_180;")


def join_ever_delinq_features():
    # everdf = everdf_tmp.merge(delinq_merge, on=['loan_id'], how='left')
    con.execute("DROP TABLE IF EXISTS ever;")
    con.execute("DROP TABLE IF EXISTS everdf;")
    con.execute("CREATE TABLE ever AS (SELECT * FROM delinq_merge);")
    # con.execute('DRPO TABLE IF EXISTS everdf;');
    # con.create_table('everdf',everdf);
    con.execute(
        "CREATE TABLE everdf AS (SELECT delinq_merge.delinquency_30 AS delinquency_30, delinq_merge.loan_id as Loan_id, delinq_merge.delinquency_90 AS delinquency_90, delinq_merge.delinquency_180 AS delinquency_180 FROM delinq_merge LEFT JOIN ever ON delinq_merge.loan_id=ever.loan_id);"
    )
    # con.execute('UPDATE everdf SET delinquency_90 =CAST (01/01/1970 AS TIMESTAMP(0)) where delinquency_90 = NULL;');
    # everdf['delinquency_30'] = everdf['delinquency_30'].fillna(np.dtype('datetime64[ms]').type('1970-01-01').astype('datetime64[ms]'))
    # everdf['delinquency_90'] = everdf['delinquency_90'].fillna(np.dtype('datetime64[ms]').type('1970-01-01').astype('datetime64[ms]'))
    # everdf['delinquency_180'] = everdf['delinquency_180'].fillna(np.dtype('datetime64[ms]').type('1970-01-01').astype('datetime64[ms]'))


def create_joined_df():
    # test = pdf[['loan_id', 'monthly_reporting_period', 'current_loan_delinquency_status', 'current_actual_upb']]
    con.execute("DROP TABLE IF EXISTS test;")
    # con.create_table('test', test)
    con.execute(
        "CREATE TABLE test AS (SELECT loan_id, monthly_reporting_period, current_loan_delinquency_status, current_actual_upb FROM perf);"
    )
    # con.execute('DROP TABLE IF EXISTS mtemp;')
    # con.execute('DROP TABLE IF EXISTS ytemp;')
    # con.execute('DROP TABLE IF EXISTS yeartemp;')
    # con.execute('DROP TABLE IF EXISTS monthtemp;')
    con.execute("DROP TABLE IF EXISTS test2;")
    # del(pdf)
    con.execute(
        "CREATE TABLE TEST2 AS SELECT EXTRACT (YEAR FROM monthly_reporting_period) timestamp_year, EXTRACT (MONTH FROM monthly_reporting_period) timestamp_month, loan_id, current_loan_delinquency_status AS delinquency_12,monthly_reporting_period AS timestamp_temp, current_actual_upb AS upb_12 FROM test"
    )
    con.execute("DROP TABLE IF EXISTS test;")
    con.execute("ALTER TABLE TEST2  RENAME TO test;")
    con.execute("UPDATE test SET upb_12 = 999999999 WHERE upb_12 = NULL;")
    con.execute("UPDATE test SET delinquency_12 = -1 WHERE delinquency_12 = NULL;")
    # test['timestamp'] = test['monthly_reporting_period']
    # test.drop(columns=['monthly_reporting_period'], inplace=True)
    # test['timestamp_month'] = test['timestamp'].dt.month
    # test['timestamp_year'] = test['timestamp'].dt.year
    # test['delinquency_12'] = test['current_loan_delinquency_status']
    # test.drop(columns=['current_loan_delinquency_status'], inplace=True)
    # test['upb_12'] = test['current_actual_upb']
    # test.drop(columns=['current_actual_upb'], inplace=True)
    # test['upb_12'] = test['upb_12'].fillna(999999999)
    # test['delinquency_12'] = test['delinquency_12'].fillna(-1)
    con.execute("DROP TABLE IF EXISTS joined_df;")
    con.execute("DROP TABLE IF EXISTS joined_df1;")

    con.execute(
        "CREATE TABLE joined_df AS SELECT test.loan_id AS loan_id,test.timestamp_temp AS timestamp_temp,test.delinquency_12 AS delinquency_12, test.upb_12 AS upb_12,test.timestamp_year AS timestamp_year ,test.timestamp_month AS timestamp_month,everdf.delinquency_30 AS delinquency_30 ,everdf.delinquency_90 AS delinquency_90,everdf.delinquency_180 AS delinquency_180 FROM test LEFT JOIN everdf  ON test.loan_id= everdf.loan_id;"
    )
    con.execute(
        "CREATE TABLE joined_df1 AS (SELECT joined_df.loan_id AS loan_id, joined_df.timestamp_temp AS timestamp_temp,joined_df.delinquency_12 AS delinquency_12, joined_df.upb_12 AS upb_12, joined_df.timestamp_year AS timestamp_year, joined_df.timestamp_month AS timestamp_month, joined_df.delinquency_30 AS delinquency_30, joined_df.delinquency_90 AS delinquency_90, joined_df.delinquency_180 AS delinquency_180, everdf1.ever_30 AS ever_30, everdf1.ever_90 AS ever_90, everdf1.ever_180 AS ever_180 FROM joined_df LEFT JOIN everdf1 ON joined_df.loan_id=everdf1.loan_id);"
    )

    # con.execute('DROP TABLE IF EXISTS everdf;')
    con.execute("DROP TABLE IF EXISTS test;")
    con.execute("DROP TABLE IF EXISTS joined_df;")
    con.execute("ALTER TABLE joined_df1 RENAME TO joined_df;")
    # del(everdf)
    # del(test)
    con.execute("UPDATE joined_df SET ever_30 = -1 WHERE ever_30 = NULL;")
    con.execute("UPDATE joined_df SET ever_90 = -1 WHERE ever_90 = NULL;")
    con.execute("UPDATE joined_df SET ever_180 = -1 WHERE ever_180 = NULL;")
    # con.execute('UPDATE joined_df SET delinquency_90 = -1  where delinquency_90 = NULL;');
    # con.execute('UPDATE joined_df SET delinquency_180 = -1  where delinquency_180 = NULL;');
    # joined_df['ever_30'] = joined_df['ever_30'].fillna(-1)
    # joined_df['ever_90'] = joined_df['ever_90'].fillna(-1)
    # joined_df['ever_180'] = joined_df['ever_180'].fillna(-1)
    # joined_df['delinquency_30'] = joined_df['delinquency_30'].fillna(-1)
    # joined_df['delinquency_90'] = joined_df['delinquency_90'].fillna(-1)
    # joined_df['delinquency_180'] = joined_df['delinquency_180'].fillna(-1)
    con.execute("UPDATE joined_df SET upb_12 = 999999999 WHERE upb_12 = NULL;")
    # Ijoined_df['timestamp_year'] = joined_df['timestamp_year'].astype('int32')
    # joined_df['timestamp_month'] = joined_df['timestamp_month'].astype('int32')

    # return joined_df
    # mapd_cursor =con.cursor()
    # query="SELECT loan_id, timestamp_temp,delinquency_12,upb_12,timestamp_year ,timestamp_month,delinquency_30 ,delinquency_90,delinquency_180,ever_30,ever_90,ever_180 from joined_df"
    # mapd_cursor.execute(query)
    # result=mapd_cursor.fetchall()
    # df =pd.DataFrame(result)
    # joined_df =df
    # df = con.select_ipc_gpu(query)
    # df =con.select_ipc_gpu(query)
    # df.head()
    # print("hahaaa")
    # print(result)
    # print(df)
    # return joined_df


def create_12_mon_features():
    testdfs = []
    n_months = 12
    for y in range(1, n_months + 1):
        string = str(y)
        months_string = str(n_months)
        # print(string)
        con.execute("DROP TABLE IF EXISTS tmpdf;")
        # con.execute('DROP TABLE IF EXISTS josh_monthstemp;')
        con.execute("DROP TABLE IF EXISTS delinq_12 ;")
        # con.execute('DROP TABLE IF EXISTS josh_monthsjoin ;');
        con.execute("DROP TABLE IF EXISTS josh_mody_ntemp ;")
        con.execute("DROP TABLE IF EXISTS finaltbl ;")
        # con.execute('SET string = y ;');
        con.execute(
            "CREATE TABLE tmpdf AS SELECT loan_id,timestamp_year,((timestamp_year * 12)+timestamp_month) AS josh_months,timestamp_month,delinquency_12,upb_12 from joined_df;"
        )
        # tmpdf = joined_df[['loan_id', 'timestamp_year', 'timestamp_month', 'delinquency_12', 'upb_12']]
        # con.execute('CREATE TABLE josh_monthstemp AS SELECT ((timestamp_year * 12)+timestamp_month) AS josh_months,loan_id FROM tmpdf;');
        # con.execute('CREATE TABLE josh_monthsjoin  AS SELECT tmpdf.loan_id AS loan_id, tmpdf.timestamp_year AS timestamp_year ,tmpdf.timestamp_month AS timestamp_month,tmpdf.delinquency_12 AS delinquency_12,tmpdf.upb_12 AS upb_12,josh_monthstemp.josh_months AS josh_months FROM tmpdf  LEFT JOIN josh_monthstemp  ON josh_monthstemp.loan_id= tmpdf.loan_id;');

        # tmpdf['josh_months'] = tmpdf['timestamp_year'] * 12 + tmpdf['timestamp_month']
        con.execute(
            "CREATE TABLE delinq_12 AS SELECT FLOOR((josh_months-24000-"
            + string
            + ")/12) AS josh_mody_n,loan_id from tmpdf;"
        )
        con.execute(
            "CREATE TABLE josh_mody_ntemp  AS SELECT tmpdf.timestamp_year AS timestamp_year ,tmpdf.timestamp_month AS timestamp_month,((delinquency_12 > 3) AND (upb_12 =0)) AS delinquency_12,tmpdf.upb_12 AS upb_12,tmpdf.josh_months AS josh_months ,tmpdf.loan_id AS loan_id, delinq_12.josh_mody_n AS josh_mody_n FROM tmpdf  LEFT JOIN delinq_12  ON tmpdf.loan_id= delinq_12.loan_id;"
        )

        # tmpdf['josh_mody_n'] = np.floor((tmpdf['josh_months'].astype('float64') - 24000 - y) / 12)

        # tmpdf = tmpdf.groupby(['loan_id', 'josh_mody_n'], as_index=False).agg({'delinquency_12': 'max','upb_12': 'min'})
        # con.execute('DROP TABLE IF EXISTS delinq_12temp;')
        con.execute("DROP TABLE IF EXISTS timestamp_yeartemp;")
        # con.execute('DROP TABLE IF EXISTS delinq_12_two;')
        # con.execute('CREATE TABLE delinq_12temp AS SELECT ((delinquency_12 >3) AND (upb_12 = 0)) AS delinquency_12 ,loan_id FROM tmpdf;');
        # con.execute('CREATE TABLE delinq_12_two  AS SELECT josh_mody_ntemp.timestamp_year AS timestamp_year ,josh_mody_ntemp.timestamp_month AS timestamp_month,josh_mody_ntemp.delinquency_12 AS delinquency_12,josh_mody_ntemp.upb_12 AS upb_12,josh_mody_ntemp.josh_months AS josh_months,josh_mody_ntemp.loan_id AS loan_id ,josh_mody_ntemp.josh_mody_n AS josh_mody_n,delinq_12temp.delinquency_12 AS delinquency_12 FROM josh_mody_ntemp  LEFT JOIN delinq_12temp  ON josh_mody_ntemp.loan_id= delinq_12temp.loan_id;');
        # tmpdf['delinquency_12'] = (tmpdf['delinquency_12']>3).astype('int32')
        # tmpdf['delinquency_12'] +=(tmpdf['upb_12']==0).astype('int32')
        # tmpdf['timestamp_year'] = np.floor(((tmpdf['josh_mody_n'] * n_months) + 24000 + (y - 1)) / 12).astype('int16')
        con.execute(
            "CREATE TABLE timestamp_yeartemp AS SELECT ((josh_mody_n * "
            + months_string
            + ") +2400 +("
            + string
            + " -1)/12) AS timestamp_year,loan_id from josh_mody_ntemp ;"
        )
        con.execute(
            "CREATE TABLE finaltbl AS SELECT josh_mody_ntemp.timestamp_month AS timestamp_month,josh_mody_ntemp.delinquency_12 AS delinquency_12,josh_mody_ntemp.upb_12 AS upb_12,josh_mody_ntemp.josh_months AS josh_months,josh_mody_ntemp.loan_id AS loan_id ,josh_mody_ntemp.josh_mody_n AS josh_mody_n,josh_mody_ntemp.delinquency_12 AS delinquency_12,timestamp_yeartemp.timestamp_year AS timestamp_year FROM josh_mody_ntemp  LEFT JOIN timestamp_yeartemp  ON timestamp_yeartemp.loan_id= josh_mody_ntemp.loan_id;"
        )
        con.execute("DROP TABLE IF EXISTS tmpdf;")
        con.execute("DROP TABLE IF EXISTS josh_monthstemp;")
        con.execute("DROP TABLE IF EXISTS delinq_12 ;")
        con.execute("DROP TABLE IF EXISTS josh_monthsjoin ;")
        con.execute("DROP TABLE IF EXISTS josh_mody_ntemp ;")
        con.execute("DROP TABLE IF EXISTS testdfs;")
        # con.execute('DROP TABLE IF EXISTS joined_df ;');
        con.execute("ALTER TABLE finaltbl RENAME TO testdfs;")
        # tmpdf['timestamp_month'] = np.int8(y)
    # tmpdf.drop(columns=['josh_mody_n'], inplace=True)
    # testdfs.append(tmpdf)
    # del(tmpdf)
    # del(joined_df)


# return pd.concat(testdfs)


def combine_joined_12_mon():
    # joined_df.drop(columns=['delinquency_12', 'upb_12'], inplace=True)
    # joined_df['timestamp_year'] = joined_df['timestamp_year'].astype('int16')
    # joined_df['timestamp_month'] = joined_df['timestamp_month'].astype('int8')
    con.execute("DROP TABLE IF EXISTS join_final ;")
    con.execute(
        "CREATE TABLE join_final AS SELECT testdfs.timestamp_year AS timestamp_year ,testdfs.timestamp_month AS timestamp_month,testdfs.loan_id AS loan_id  FROM testdfs  LEFT JOIN joined_df  ON testdfs.loan_id= joined_df.loan_id;"
    )
    con.execute("DROP TABLE IF EXISTS joined_df ;")
    con.execute("ALTER TABLE join_final RENAME TO joined_df;")
    con.execute("DROP TABLE IF EXISTS join_final ;")

    # return joined_df.merge(testdf, how='left', on=['loan_id', 'timestamp_year', 'timestamp_month'])


def final_performance_delinquency():
    # merged = pdf[['loan_id', 'monthly_reporting_period']]
    # everdf1 = pdf[['loan_id', 'current_loan_delinquency_status']]
    con.execute("DROP TABLE IF EXISTS mergedtemp;")
    con.execute("CREATE TABLE mergedtemp AS (SELECT loan_id, monthly_reporting_period FROM perf);")
    # con.create_table('mergedtemp', merged)
    # merged['timestamp_month'] = merged['monthly_reporting_period'].dt.month
    # merged['timestamp_month'] = merged['timestamp_month'].astype('int8')
    # merged['timestamp_year'] = merged['monthly_reporting_period'].dt.year
    # merged['timestamp_year'] = merged['timestamp_year'].astype('int16')
    # merged = merged.merge(joined_df, how='left', on=['loan_id', 'timestamp_year', 'timestamp_month'])
    con.execute("DROP TABLE IF EXISTS merged_temp")
    con.execute("DROP TABLE IF EXISTS merged")
    # con.execute('SELECT loan_id,monthly_reporting_period FROM merged;');
    con.execute(
        "CREATE TABLE merged_temp AS SELECT EXTRACT (MONTH FROM monthly_reporting_period) timestamp_month,EXTRACT(YEAR FROM monthly_reporting_period) timestamp_year,loan_id FROM mergedtemp ;"
    )
    con.execute(
        "CREATE TABLE merged AS SELECT joined_df.timestamp_year AS time_stamp_year,joined_df.timestamp_month AS time_stamp_month,joined_df.loan_id AS loan_id  FROM merged_temp LEFT JOIN joined_df ON merged_temp.loan_id=joined_df.loan_id AND merged_temp.timestamp_year=joined_df.timestamp_year AND merged_temp.timestamp_month=joined_df.timestamp_month"
    )
    # con.execute('UPDATE merged SET time_stamp_year = CAST (time_stamp_year  AS DATE ENCODING FIXED(16));');
    con.execute("DROP TABLE IF EXISTS merged_temp")
    # merged.drop(columns=['timestamp_year'], inplace=True)
    # merged.drop(columns=['timestamp_month'], inplace=True)


def join_perf_acq_pdfs():
    # return perf.merge(acq, how='left', on=['loan_id'])
    con.execute("DROP TABLE IF EXISTS tempperf ")
    con.execute(
        "CREATE TABLE tempperf AS SELECT acq.loan_id AS loan_id,acq.seller_name FROM acq LEFT JOIN perf ON acq.loan_id = perf.loan_id;"
    )


def last_mile_cleaning(df, **kwargs):
    # for col, dtype in df.dtypes.iteritems():
    #    if str(dtype)=='category':
    #        df[col] = df[col].cat.codes
    # df['delinquency_12'] = df['delinquency_12'] > 0
    # df['delinquency_12'] = df['delinquency_12'].fillna(False).astype('int32')
    return df  # .to_arrow(index=False)


# Load database reporting functions
pathToReportDir = os.path.join(pathlib.Path(__file__).parent, "..", "report")
print(pathToReportDir)
sys.path.insert(1, pathToReportDir)

parser = argparse.ArgumentParser(description="Run Mortgage benchmark using pandas")

parser.add_argument(
    "-fs",
    dest="fragment_size",
    action="append",
    type=int,
    help="Fragment size to use for created table. Multiple values are allowed and encouraged.",
)
parser.add_argument("-r", default="report_pandas.csv", help="Report file name.")
parser.add_argument(
    "-df",
    default=1,
    type=int,
    help="Number of datafiles (quarters) to input into database for processing.",
)
parser.add_argument(
    "-dp",
    required=True,
    help="Path to root of mortgage datafiles directory (contains names.csv).",
)
parser.add_argument(
    "-i",
    dest="iterations",
    default=5,
    type=int,
    help="Number of iterations to run every benchmark. Best result is selected.",
)
parser.add_argument(
    "-port",
    default=62074,
    type=int,
    help="TCP port that omnisql client should use to connect to server",
)

parser.add_argument("-db-server", default="localhost", help="Host name of MySQL server")
parser.add_argument("-db-port", default=3306, type=int, help="Port number of MySQL server")
parser.add_argument(
    "-db-user",
    default="",
    help="Username to use to connect to MySQL database. If user name is specified, script attempts to store results in MySQL database using other -db-* parameters.",
)
parser.add_argument(
    "-db-pass", default="omniscidb", help="Password to use to connect to MySQL database"
)
parser.add_argument(
    "-db-name", default="omniscidb", help="MySQL database to use to store benchmark results",
)
parser.add_argument("-db-table", help="Table to use to store results for this benchmark.")

parser.add_argument(
    "-commit",
    default="1234567890123456789012345678901234567890",
    help="Commit hash to use to record this benchmark results",
)

args = parser.parse_args()

if args.df <= 0:
    print("Bad number of data files specified", args.df)
    sys.exit(1)

if args.iterations < 1:
    print("Bad number of iterations specified", args.t)

con = connect(
    user="admin", password="HyperInteractive", host="localhost", dbname="omnisci", port=args.port,
)

db_reporter = None
if args.db_user is not "":
    print("Connecting to database")
    db = mysql.connector.connect(
        host=args.db_server,
        port=args.db_port,
        user=args.db_user,
        passwd=args.db_pass,
        db=args.db_name,
    )
    db_reporter = report.DbReport(
        db,
        args.db_table,
        {
            "FilesNumber": "INT UNSIGNED NOT NULL",
            "FragmentSize": "BIGINT UNSIGNED NOT NULL",
            "BenchName": "VARCHAR(500) NOT NULL",
            "BestExecTimeMS": "BIGINT UNSIGNED",
            "BestTotalTimeMS": "BIGINT UNSIGNED",
            "WorstExecTimeMS": "BIGINT UNSIGNED",
            "WorstTotalTimeMS": "BIGINT UNSIGNED",
            "AverageExecTimeMS": "BIGINT UNSIGNED",
            "AverageTotalTimeMS": "BIGINT UNSIGNED",
        },
        {"ScriptName": "mortgage_pandas.py", "CommitHash": args.commit},
    )

data_directory = args.dp
benchName = "mortgage"

perf_data_path = os.path.join(data_directory, "perf")
perf_format_path = os.path.join(perf_data_path, "Performance_%sQ%s.txt")
bestExecTime = float("inf")
bestTotalTime = float("inf")
worstExecTime = 0
worstTotalTime = 0
avgExecTime = 0
avgTotalTime = 0

for fs in args.fragment_size:
    for iii in range(1, args.iterations + 1):
        dataFilesNumber = 0
        time_ETL = time.time()
        exec_time_total = 0
        print("RUNNING BENCHMARK NUMBER", benchName, "ITERATION NUMBER", iii)
        for quarter in range(0, args.df):
            year = 2000 + quarter // 4
            perf_file = perf_format_path % (str(year), str(quarter % 4 + 1))

            files = [
                f
                for f in pathlib.Path(perf_data_path).iterdir()
                if f.match("Performance_%sQ%s.txt*" % (str(year), str(quarter % 4 + 1)))
            ]
            for f in files:
                dataframe, exec_time = run_pd_workflow(
                    year=year, quarter=(quarter % 4 + 1), perf_file=str(f), fragment_size=fs,
                )
                exec_time_total += exec_time
            dataFilesNumber += 1
        time_ETL_end = time.time()
        ttt = (time_ETL_end - time_ETL) * 1000
        print("ITERATION", iii, "EXEC TIME: ", exec_time_total, "TOTAL TIME: ", ttt)

        if bestExecTime > exec_time_total:
            bestExecTime = exec_time_total
        if worstExecTime < exec_time_total:
            worstExecTime = exec_time_total
        avgExecTime += exec_time_total
        if bestTotalTime > ttt:
            bestTotalTime = ttt
        if worstTotalTime < ttt:
            bestTotalTime = ttt
        avgTotalTime += ttt

avgExecTime /= args.iterations
avgTotalTime /= args.iterations

try:
    with open(args.r, "w") as report:
        print(
            "BENCHMARK", benchName, "EXEC TIME", bestExecTime, "TOTAL TIME", bestTotalTime,
        )
        print(
            "datafiles,fragment_size,query,query_exec_min,query_total_min,query_exec_max,query_total_max,query_exec_avg,query_total_avg,query_error_info",
            file=report,
            flush=True,
        )
        print(
            dataFilesNumber,
            ",",
            0,
            ",",
            benchName,
            ",",
            bestExecTime,
            ",",
            bestTotalTime,
            ",",
            worstExecTime,
            ",",
            worstTotalTime,
            ",",
            avgExecTime,
            ",",
            avgTotalTime,
            ",",
            "",
            "\n",
            file=report,
            sep="",
            end="",
            flush=True,
        )
        if db_reporter is not None:
            db_reporter.submit(
                {
                    "FilesNumber": dataFilesNumber,
                    "FragmentSize": 0,
                    "BenchName": benchName,
                    "BestExecTimeMS": bestExecTime,
                    "BestTotalTimeMS": bestTotalTime,
                    "WorstExecTimeMS": worstExecTime,
                    "WorstTotalTimeMS": worstTotalTime,
                    "AverageExecTimeMS": avgExecTime,
                    "AverageTotalTimeMS": avgTotalTime,
                }
            )
except IOError as err:
    print("Failed writing report file", args.r, err)
